{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOpjySm8PHEZLILt8hT4/0s",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Lanisha20/ECEN-360/blob/main/FHTH_v1_5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-3mLBE3Dmrtd"
      },
      "outputs": [],
      "source": [
        "# From Hashtags to Hangars: Fashion Sales Forecast Model\n",
        "\n",
        "# INSTALLS (Uncomment if running for first time)\n",
        "#!pip install xgboost textblob seaborn matplotlib snscrape pytrends prophet streamlit\n",
        "# allows for multiple files & multi-trend input"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_absolute_error, r2_score\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from xgboost import XGBRegressor\n",
        "from pytrends.request import TrendReq\n",
        "from prophet import Prophet\n",
        "import streamlit as st\n",
        "import time\n",
        "import random"
      ],
      "metadata": {
        "id": "dOKBFE7kmxiT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------------------------------------\n",
        "# MULTI-FILE UPLOAD + COMPARISON\n",
        "# ----------------------------------------\n",
        "def load_multiple_csv(files):\n",
        "    dfs = []\n",
        "    for file in files:\n",
        "        df = load_and_clean_csv(file)\n",
        "        dfs.append(df)\n",
        "    return dfs\n",
        "\n",
        "def compare_multiple_datasets(dfs, labels):\n",
        "    st.subheader(\"Comparison of Multiple Sales Datasets\")\n",
        "    combined_data = []\n",
        "\n",
        "    for df, label in zip(dfs, labels):\n",
        "        monthly_sales = df.groupby('Month')['Purchase Amount (USD)'].sum().reset_index()\n",
        "        monthly_sales['Dataset'] = label\n",
        "        combined_data.append(monthly_sales)\n",
        "\n",
        "    combined_df = pd.concat(combined_data)\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(12,6))\n",
        "    sns.lineplot(data=combined_df, x='Month', y='Purchase Amount (USD)', hue='Dataset', marker='o')\n",
        "    plt.title(\"Monthly Sales Comparison\")\n",
        "    st.pyplot(fig)\n",
        "\n",
        "# ----------------------------------------\n",
        "# STEP 1: Load + Clean the CSV (Updated to include Price and Review Rating)\n",
        "# ----------------------------------------\n",
        "def load_and_clean_csv(filepath):\n",
        "    df = pd.read_csv(filepath)\n",
        "    df['Date Purchase'] = pd.to_datetime(df['Date Purchase'], errors='coerce')\n",
        "    df = df.dropna(subset=['Date Purchase', 'Purchase Amount (USD)', 'Item Purchased'])\n",
        "    if 'Price' not in df.columns:\n",
        "        df['Price'] = np.random.uniform(10, 500, size=len(df))  # Mock price if not present\n",
        "    if 'Review Rating' not in df.columns:\n",
        "        df['Review Rating'] = np.random.uniform(1, 5, size=len(df))  # Mock ratings if not present\n",
        "    df['Month'] = df['Date Purchase'].dt.month\n",
        "    df['Week'] = df['Date Purchase'].dt.isocalendar().week.astype(int)\n",
        "    df['Item_Code'] = df['Item Purchased'].astype('category').cat.codes\n",
        "    return df\n",
        "\n",
        "# ----------------------------------------\n",
        "# STEP 2: Visualize Data\n",
        "# ----------------------------------------\n",
        "def visualize_sales(df):\n",
        "    st.subheader(\"Total Sales per Month\")\n",
        "    monthly_sales = df.groupby('Month')['Purchase Amount (USD)'].sum().reset_index()\n",
        "    fig, ax = plt.subplots(figsize=(10,5))\n",
        "    sns.barplot(data=monthly_sales, x='Month', y='Purchase Amount (USD)', ci=None)\n",
        "    st.pyplot(fig)\n",
        "\n",
        "    st.subheader(\"Sales Distribution for Top Items\")\n",
        "    top_items = df['Item Purchased'].value_counts().head(10).index\n",
        "    fig, ax = plt.subplots(figsize=(10,5))\n",
        "    sns.boxplot(data=df[df['Item Purchased'].isin(top_items)], x='Item Purchased', y='Purchase Amount (USD)')\n",
        "    plt.xticks(rotation=45)\n",
        "    st.pyplot(fig)\n",
        "\n",
        "# ----------------------------------------\n",
        "# UPDATED INDIVIDUAL DATASET ANALYTICS WITH BUTTONS AND SIDE-BY-SIDE LAYOUT\n",
        "# ----------------------------------------\n",
        "\n",
        "def individual_dataset_analytics(datasets, labels):\n",
        "    st.header(\"Individual Dataset Analytics\")\n",
        "    if \"show_analytics\" not in st.session_state:\n",
        "        st.session_state[\"show_analytics\"] = False\n",
        "\n",
        "    if st.button(\"Show Analytics for All Datasets\") or st.session_state[\"show_analytics\"]:\n",
        "        st.session_state[\"show_analytics\"] = True\n",
        "\n",
        "        cols = st.columns(len(datasets))\n",
        "        for col, df, label in zip(cols, datasets, labels):\n",
        "            with col:\n",
        "                st.subheader(f\"Analytics for {label}\")\n",
        "                visualize_sales(df)\n",
        "                model = train_sales_predictors(df)\n",
        "\n",
        "                trends_input = st.text_input(f\"Enter trends to forecast for {label} (comma-separated):\", key=f\"forecast_{label}\")\n",
        "                if trends_input:\n",
        "                    trend_list = [trend.strip() for trend in trends_input.split(\",\")]\n",
        "                    forecast_multiple_trends(trend_list)\n",
        "\n",
        "                forecast_months = st.slider(f\"Select forecast months for {label}\", min_value=3, max_value=24, value=6, key=f\"months_{label}\")\n",
        "                forecast_total_sales(df, periods=forecast_months)\n",
        "\n",
        "                predict_top_items(df, model)\n",
        "\n",
        "                st.markdown(\"---\")\n",
        "\n",
        "# ----------------------------------------\n",
        "# STEP 3: Train Sales Predictors (Upgraded with XGBoost and Random Forest)\n",
        "# ----------------------------------------\n",
        "def train_sales_predictors(df):\n",
        "    features = ['Month', 'Week', 'Item_Code', 'Price', 'Review Rating']\n",
        "    X = df[features]\n",
        "    y = df['Purchase Amount (USD)']\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    xgb_model = XGBRegressor(n_estimators=50, learning_rate=0.1, random_state=42)\n",
        "    rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "\n",
        "    xgb_model.fit(X_train, y_train)\n",
        "    rf_model.fit(X_train, y_train)\n",
        "\n",
        "    xgb_preds = xgb_model.predict(X_test)\n",
        "    rf_preds = rf_model.predict(X_test)\n",
        "\n",
        "    xgb_mae = mean_absolute_error(y_test, xgb_preds)\n",
        "    xgb_r2 = r2_score(y_test, xgb_preds)\n",
        "\n",
        "    rf_mae = mean_absolute_error(y_test, rf_preds)\n",
        "    rf_r2 = r2_score(y_test, rf_preds)\n",
        "\n",
        "    st.subheader(\"Model Performance\")\n",
        "    st.write(f\"XGBoost MAE: {xgb_mae:.2f}, R²: {xgb_r2:.2f}\")\n",
        "    st.write(f\"Random Forest MAE: {rf_mae:.2f}, R²: {rf_r2:.2f}\")\n",
        "\n",
        "    st.subheader(\"Feature Importance (XGBoost)\")\n",
        "    importance = xgb_model.feature_importances_\n",
        "    importance_df = pd.DataFrame({'Feature': features, 'Importance': importance}).sort_values(by='Importance', ascending=False)\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(10,5))\n",
        "    sns.barplot(data=importance_df, x='Feature', y='Importance')\n",
        "    plt.title('Feature Importance')\n",
        "    st.pyplot(fig)\n",
        "\n",
        "    return xgb_model\n",
        "\n",
        "# # ----------------------------------------\n",
        "# # MULTI-TREND FORECASTING FUNCTION\n",
        "# # ----------------------------------------\n",
        "# def forecast_multiple_trends(keywords, days=7):\n",
        "#     pytrends = TrendReq(hl='en-US', tz=360)\n",
        "#     fig, ax = plt.subplots(figsize=(12,6))\n",
        "\n",
        "#     for keyword in keywords:\n",
        "#         pytrends.build_payload([keyword], cat=0, timeframe='today 3-m')\n",
        "#         df = pytrends.interest_over_time()\n",
        "\n",
        "#         if not df.empty:\n",
        "#             df = df.drop(columns='isPartial').reset_index().rename(columns={keyword: 'y', 'date': 'ds'})\n",
        "#             model = Prophet()\n",
        "#             model.fit(df)\n",
        "#             future = model.make_future_dataframe(periods=days)\n",
        "#             forecast = model.predict(future)\n",
        "#             ax.plot(forecast['ds'], forecast['yhat'], label=keyword)\n",
        "\n",
        "#     ax.set_title(\"Trend Forecasts\")\n",
        "#     ax.set_xlabel(\"Date\")\n",
        "#     ax.set_ylabel(\"Trend Popularity\")\n",
        "#     ax.legend()\n",
        "#     st.pyplot(fig)\n",
        "\n",
        "# ----------------------------------------\n",
        "# UPDATED FUNCTION: FORECAST MULTIPLE TRENDS (SIMULATED)\n",
        "# ----------------------------------------\n",
        "\n",
        "def forecast_multiple_trends(keywords, days=90):\n",
        "    st.subheader(\"Forecasted Trends (Simulated)\")\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(12,6))\n",
        "\n",
        "    for keyword in keywords:\n",
        "        # Simulate a realistic trend curve\n",
        "        dates = pd.date_range(start=pd.Timestamp.now() - pd.Timedelta(days=90), periods=90)\n",
        "        scores = np.clip(np.random.normal(loc=50, scale=15, size=90), 10, 100)\n",
        "\n",
        "        trend_df = pd.DataFrame({\n",
        "            'ds': dates,\n",
        "            'y': scores\n",
        "        })\n",
        "\n",
        "        model = Prophet()\n",
        "        model.fit(trend_df)\n",
        "        future = model.make_future_dataframe(periods=days)\n",
        "        forecast = model.predict(future)\n",
        "        ax.plot(forecast['ds'], forecast['yhat'], label=keyword)\n",
        "\n",
        "    ax.set_title(\"Trend Forecasts (Simulated)\")\n",
        "    ax.set_xlabel(\"Date\")\n",
        "    ax.set_ylabel(\"Trend Popularity\")\n",
        "    ax.legend()\n",
        "    st.pyplot(fig)\n",
        "\n",
        "# ----------------------------------------\n",
        "# (Other Functions: forecast_total_sales, predict_top_items remain the same)\n",
        "# ----------------------------------------\n",
        "# ----------------------------------------\n",
        "# FORECAST TOTAL FUTURE SALES\n",
        "# ----------------------------------------\n",
        "def forecast_total_sales(df, periods=6):\n",
        "    sales_df = df[['Date Purchase', 'Purchase Amount (USD)']].rename(columns={\n",
        "        'Date Purchase': 'ds',\n",
        "        'Purchase Amount (USD)': 'y'\n",
        "    })\n",
        "    sales_df = sales_df.groupby('ds').sum().reset_index()\n",
        "\n",
        "    model = Prophet()\n",
        "    model.fit(sales_df)\n",
        "    future = model.make_future_dataframe(periods=periods, freq='M')\n",
        "    forecast = model.predict(future)\n",
        "\n",
        "    st.subheader(\"Forecasted Total Sales\")\n",
        "    fig2 = model.plot(forecast)\n",
        "    st.pyplot(fig2)\n",
        "\n",
        "    return forecast[['ds', 'yhat']]\n",
        "\n",
        "# ----------------------------------------\n",
        "# PREDICT TOP SELLING ITEMS\n",
        "# ----------------------------------------\n",
        "def predict_top_items(df, model):\n",
        "    latest_month = df['Month'].max()\n",
        "    predict_df = df[df['Month'] == latest_month][['Month', 'Week', 'Item_Code', 'Price', 'Review Rating']]\n",
        "    predict_df['Month'] = (predict_df['Month'] % 12) + 1  # simulate next month\n",
        "\n",
        "    preds = model.predict(predict_df)\n",
        "    predict_df['Predicted_Sales'] = preds\n",
        "    predict_df['Item Purchased'] = df[df['Month'] == latest_month]['Item Purchased'].values\n",
        "\n",
        "    top_items = predict_df.groupby('Item Purchased')['Predicted_Sales'].sum().sort_values(ascending=False).head(10)\n",
        "\n",
        "    st.subheader(\"Top 10 Predicted Best-Selling Items (Next Month)\")\n",
        "    fig, ax = plt.subplots(figsize=(10,5))\n",
        "    sns.barplot(x=top_items.index, y=top_items.values)\n",
        "    plt.xticks(rotation=45)\n",
        "    st.pyplot(fig)\n",
        "\n",
        "# ----------------------------------------\n",
        "# UPDATED FUNCTION: CORRELATE TRENDS WITH DATASETS (SIMULATED TREND SCORES)\n",
        "# ----------------------------------------\n",
        "\n",
        "def correlate_trends_with_datasets(datasets, labels, keywords):\n",
        "    st.subheader(\"Correlate Trends with Sales by Dataset (Simulated)\")\n",
        "\n",
        "    correlation_results = []\n",
        "\n",
        "    for keyword in keywords:\n",
        "        trend_monthly = pd.DataFrame({\n",
        "            'Month': list(range(1, 13)),\n",
        "            keyword: [random.uniform(30, 80) for _ in range(12)]\n",
        "        })\n",
        "\n",
        "        for df, label in zip(datasets, labels):\n",
        "            sales_monthly = df.groupby('Month')['Purchase Amount (USD)'].sum().reset_index()\n",
        "            merged = pd.merge(trend_monthly, sales_monthly, on='Month', how='inner')\n",
        "            if len(merged) > 1:\n",
        "                corr = merged[keyword].corr(merged['Purchase Amount (USD)'])\n",
        "                correlation_results.append({\"Dataset\": label, \"Trend\": keyword, \"Correlation\": corr})\n",
        "\n",
        "    if correlation_results:\n",
        "        corr_df = pd.DataFrame(correlation_results)\n",
        "        st.dataframe(corr_df)\n",
        "    else:\n",
        "        st.warning(\"No trend correlation results available.\")\n",
        "\n",
        "# ----------------------------------------\n",
        "# UPDATED FUNCTION: TREND IMPACT MODELING (SIMULATED)\n",
        "# ----------------------------------------\n",
        "\n",
        "def trend_impact_modeling(datasets, labels, keywords):\n",
        "    st.subheader(\"Trend Impact Modeling on Sales (Simulated)\")\n",
        "\n",
        "    impact_results = []\n",
        "\n",
        "    for keyword in keywords:\n",
        "        trend_monthly = pd.DataFrame({\n",
        "            'Month': list(range(1, 13)),\n",
        "            keyword: [random.uniform(30, 80) for _ in range(12)]\n",
        "        })\n",
        "\n",
        "        for df, label in zip(datasets, labels):\n",
        "            sales_monthly = df.groupby('Month')['Purchase Amount (USD)'].sum().reset_index()\n",
        "            merged = pd.merge(trend_monthly, sales_monthly, on='Month', how='inner')\n",
        "            if len(merged) > 1:\n",
        "                X = merged[[keyword]].values\n",
        "                y = merged['Purchase Amount (USD)'].values\n",
        "                model = LinearRegression()\n",
        "                model.fit(X, y)\n",
        "                coef = model.coef_[0]\n",
        "                impact_results.append({\"Dataset\": label, \"Trend\": keyword, \"Impact Coefficient\": coef})\n",
        "\n",
        "    if impact_results:\n",
        "        impact_df = pd.DataFrame(impact_results)\n",
        "        st.dataframe(impact_df)\n",
        "    else:\n",
        "        st.warning(\"No impact modeling results available.\")\n",
        "\n",
        "# ----------------------------------------\n",
        "# MASTER FORECASTING AND BEST DATASET DETECTION SECTION\n",
        "# ----------------------------------------\n",
        "\n",
        "def detect_best_dataset(datasets, labels, trends):\n",
        "    st.subheader(\"Auto-Detect Best Dataset by Trend Correlation\")\n",
        "    pytrends = TrendReq(hl='en-US', tz=360)\n",
        "    best_dataset = None\n",
        "    best_score = -2\n",
        "\n",
        "    for df, label in zip(datasets, labels):\n",
        "        total_corr = 0\n",
        "        count = 0\n",
        "\n",
        "        for trend in trends:\n",
        "            try:\n",
        "                pytrends.build_payload([trend], cat=0, timeframe='today 3-m')\n",
        "                trend_df = pytrends.interest_over_time()\n",
        "                if not trend_df.empty:\n",
        "                    trend_df = trend_df.drop(columns='isPartial').reset_index()\n",
        "                    trend_df['Month'] = trend_df['date'].dt.month\n",
        "                    trend_monthly = trend_df.groupby('Month')[trend].mean().reset_index()\n",
        "\n",
        "                    sales_monthly = df.groupby('Month')['Purchase Amount (USD)'].sum().reset_index()\n",
        "                    merged = pd.merge(trend_monthly, sales_monthly, on='Month', how='inner')\n",
        "                    if len(merged) > 1:\n",
        "                        corr = merged[trend].corr(merged['Purchase Amount (USD)'])\n",
        "                        if not pd.isna(corr):\n",
        "                            total_corr += corr\n",
        "                            count += 1\n",
        "            except:\n",
        "                pass\n",
        "\n",
        "        avg_corr = total_corr / count if count > 0 else -2\n",
        "        if avg_corr > best_score:\n",
        "            best_score = avg_corr\n",
        "            best_dataset = label\n",
        "\n",
        "    if best_dataset:\n",
        "        st.success(f\"The dataset most aligned with fashion trends is: **{best_dataset}** (Avg Corr: {best_score:.2f})\")\n",
        "    else:\n",
        "        st.warning(\"No strong correlations detected.\")\n",
        "\n",
        "\n",
        "def master_combined_forecast(datasets, labels):\n",
        "    st.subheader(\"Master Combined Forecast Across Datasets\")\n",
        "    combined_df = pd.concat(datasets)\n",
        "    combined_df = combined_df[['Date Purchase', 'Purchase Amount (USD)']].rename(columns={\n",
        "        'Date Purchase': 'ds',\n",
        "        'Purchase Amount (USD)': 'y'\n",
        "    })\n",
        "    combined_df = combined_df.groupby('ds').sum().reset_index()\n",
        "\n",
        "    model = Prophet()\n",
        "    model.fit(combined_df)\n",
        "    future = model.make_future_dataframe(periods=12, freq='M')\n",
        "    forecast = model.predict(future)\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(12,6))\n",
        "    model.plot(forecast, ax=ax)\n",
        "    plt.title(\"Master Combined Sales Forecast\")\n",
        "    st.pyplot(fig)\n",
        "\n",
        "def scrape_top_fashion_trends():\n",
        "    st.subheader(\"Live Google Trends Scraper for Fashion Trends\")\n",
        "    pytrends = TrendReq(hl='en-US', tz=360)\n",
        "    try:\n",
        "        trending_searches_df = pytrends.trending_searches(pn='united_states')\n",
        "        fashion_keywords = [trend for trend in trending_searches_df[0].tolist() if any(fashion_word in trend.lower() for fashion_word in ['fashion', 'outfit', 'style', 'look', 'wear', 'clothing', 'apparel'])]\n",
        "\n",
        "        if fashion_keywords:\n",
        "            st.success(f\"🧵 Detected {len(fashion_keywords)} fashion-related trending keywords!\")\n",
        "            st.write(fashion_keywords)\n",
        "            return fashion_keywords\n",
        "        else:\n",
        "            st.warning(\"No fashion-related trends detected right now.\")\n",
        "            return []\n",
        "    except Exception as e:\n",
        "        st.error(f\"Error scraping Google Trends: {e}\")\n",
        "        return []\n",
        "\n",
        "# ----------------------------------------\n",
        "# UPDATED FUNCTION: SENTIMENT ANALYSIS ON TRENDS (SIMULATED)\n",
        "# ----------------------------------------\n",
        "\n",
        "def sentiment_analysis_on_trends(trends):\n",
        "    st.subheader(\"Sentiment Analysis on Trends (Simulated)\")\n",
        "\n",
        "    sentiments = {}\n",
        "    for trend in trends:\n",
        "        roll = random.random()\n",
        "        if roll < 0.6:\n",
        "            sentiment = random.uniform(0.2, 1.0)  # positive\n",
        "        elif roll < 0.9:\n",
        "            sentiment = random.uniform(-0.2, 0.2)  # neutral\n",
        "        else:\n",
        "            sentiment = random.uniform(-1.0, -0.2)  # negative\n",
        "        sentiments[trend] = sentiment\n",
        "\n",
        "    sentiment_df = pd.DataFrame({\n",
        "        'Trend': list(sentiments.keys()),\n",
        "        'Sentiment Score': list(sentiments.values())\n",
        "    })\n",
        "\n",
        "    st.dataframe(sentiment_df)\n",
        "\n",
        "    return sentiments\n",
        "\n",
        "# # ----------------------------------------\n",
        "# # TREND IMPACT MODELING (Simple Regression Model)\n",
        "# # ----------------------------------------\n",
        "# from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# def trend_impact_modeling(datasets, labels, trends):\n",
        "#     st.subheader(\"Trend Impact Modeling on Sales\")\n",
        "#     pytrends = TrendReq(hl='en-US', tz=360)\n",
        "\n",
        "#     impact_results = []\n",
        "\n",
        "#     for trend in trends:\n",
        "#         pytrends.build_payload([trend], cat=0, timeframe='today 3-m')\n",
        "#         trend_df = pytrends.interest_over_time()\n",
        "\n",
        "#         if not trend_df.empty:\n",
        "#             trend_df = trend_df.drop(columns='isPartial').reset_index()\n",
        "#             trend_df['Month'] = trend_df['date'].dt.month\n",
        "#             trend_monthly = trend_df.groupby('Month')[trend].mean().reset_index()\n",
        "\n",
        "#             for df, label in zip(datasets, labels):\n",
        "#                 sales_monthly = df.groupby('Month')['Purchase Amount (USD)'].sum().reset_index()\n",
        "#                 merged = pd.merge(trend_monthly, sales_monthly, on='Month', how='inner')\n",
        "#                 if len(merged) > 1:\n",
        "#                     X = merged[[trend]].values\n",
        "#                     y = merged['Purchase Amount (USD)'].values\n",
        "#                     model = LinearRegression()\n",
        "#                     model.fit(X, y)\n",
        "#                     coef = model.coef_[0]\n",
        "#                     impact_results.append({\"Dataset\": label, \"Trend\": trend, \"Impact Coefficient\": coef})\n",
        "\n",
        "#     if impact_results:\n",
        "#         impact_df = pd.DataFrame(impact_results)\n",
        "#         st.dataframe(impact_df)\n",
        "\n",
        "# ----------------------------------------\n",
        "# SALES BOOST FORECASTING BASED ON TRENDS\n",
        "# ----------------------------------------\n",
        "\n",
        "def sales_boost_forecast(df, selected_trends):\n",
        "    st.subheader(\"Sales Boost Forecast Based on Selected Trends\")\n",
        "    pytrends = TrendReq(hl='en-US', tz=360)\n",
        "    future_trend_score = 0\n",
        "\n",
        "    for trend in selected_trends:\n",
        "        pytrends.build_payload([trend], cat=0, timeframe='now 7-d')\n",
        "        trend_df = pytrends.interest_over_time()\n",
        "        if not trend_df.empty:\n",
        "            score = trend_df[trend].mean()\n",
        "            future_trend_score += score\n",
        "\n",
        "    future_trend_score = future_trend_score / len(selected_trends) if selected_trends else 0\n",
        "\n",
        "    sales_df = df[['Date Purchase', 'Purchase Amount (USD)']].rename(columns={\n",
        "        'Date Purchase': 'ds',\n",
        "        'Purchase Amount (USD)': 'y'\n",
        "    })\n",
        "    sales_df = sales_df.groupby('ds').sum().reset_index()\n",
        "\n",
        "    model = Prophet()\n",
        "    model.fit(sales_df)\n",
        "    future = model.make_future_dataframe(periods=6, freq='M')\n",
        "    forecast = model.predict(future)\n",
        "\n",
        "    forecast['yhat_adjusted'] = forecast['yhat'] * (1 + future_trend_score / 100)\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(12,6))\n",
        "    ax.plot(forecast['ds'], forecast['yhat'], label='Base Forecast')\n",
        "    ax.plot(forecast['ds'], forecast['yhat_adjusted'], label='Boosted Forecast', linestyle='--')\n",
        "    plt.title(\"Sales Boost Forecast\")\n",
        "    plt.legend()\n",
        "    st.pyplot(fig)\n",
        "\n",
        "# ----------------------------------------\n",
        "# RECOMMENDATION ENGINE\n",
        "# ----------------------------------------\n",
        "\n",
        "def recommendation_engine(trends, sentiments):\n",
        "    st.subheader(\"Fashion Investment Recommendations\")\n",
        "\n",
        "    recommendations = []\n",
        "    for trend in trends:\n",
        "        sentiment = sentiments.get(trend, 0)\n",
        "        if sentiment > 0.2:\n",
        "            recommendations.append(f\"✅ Invest more in {trend} category!\")\n",
        "        elif sentiment < -0.2:\n",
        "            recommendations.append(f\"⚠️ Caution advised for {trend} category.\")\n",
        "\n",
        "    if recommendations:\n",
        "        for r in recommendations:\n",
        "            st.write(r)\n",
        "    else:\n",
        "        st.info(\"No strong investment signals detected from sentiment analysis.\")\n",
        "\n",
        "# ----------------------------------------\n",
        "# FUTURE FASHION INDEX\n",
        "# ----------------------------------------\n",
        "\n",
        "def future_fashion_index(trends):\n",
        "    st.subheader(\"Future Fashion Index Tracker\")\n",
        "\n",
        "    if not trends:\n",
        "        st.warning(\"No trends provided.\")\n",
        "        return\n",
        "\n",
        "    index_scores = []\n",
        "\n",
        "    for trend in trends:\n",
        "        # Simulate a score between 30 and 80\n",
        "        score = random.uniform(30, 80)\n",
        "        index_scores.append(score)\n",
        "\n",
        "    if index_scores:\n",
        "        fashion_index = sum(index_scores) / len(index_scores)\n",
        "        st.metric(label=\"Fashion Index Score\", value=f\"{fashion_index:.2f}\")\n",
        "    else:\n",
        "        st.warning(\"Not enough trend data to calculate index.\")\n",
        "\n",
        "\n",
        "# ----------------------------------------\n",
        "# INTEGRATION INTO MAIN STREAMLIT APP FLOW\n",
        "# ----------------------------------------\n",
        "\n",
        "st.title(\"From Hashtags to Hangars: Fashion Forecasting Dashboard\")\n",
        "\n",
        "uploaded_files = st.file_uploader(\"Upload one or more Fashion Sales CSVs\", type=[\"csv\"], accept_multiple_files=True)\n",
        "\n",
        "if uploaded_files:\n",
        "    datasets = load_multiple_csv(uploaded_files)\n",
        "    dataset_labels = [file.name for file in uploaded_files]\n",
        "\n",
        "    st.header(\"Forecast Manual Trends\")\n",
        "    trends_input = st.text_input(\"Enter multiple fashion trends separated by commas (e.g., barbiecore, grunge, Y2K)\")\n",
        "    if trends_input:\n",
        "        trend_list = [trend.strip() for trend in trends_input.split(\",\")]\n",
        "        forecast_multiple_trends(trend_list)\n",
        "        sentiments = sentiment_analysis_on_trends(trend_list)\n",
        "        st.header(\"Sentiment Analysis on Entered Trends\")\n",
        "        st.write(sentiments)\n",
        "\n",
        "        st.header(\"Investment Recommendations Based on Trend Sentiment\")\n",
        "        recommendation_engine(trend_list, sentiments)\n",
        "\n",
        "        st.header(\"Future Fashion Index\")\n",
        "        future_fashion_index(trend_list)\n",
        "\n",
        "    if len(datasets) == 1:\n",
        "        df = datasets[0]\n",
        "        visualize_sales(df)\n",
        "        model = train_sales_predictors(df)\n",
        "\n",
        "        st.header(\"Future Sales Forecast\")\n",
        "        forecast_months = st.slider(\"Select number of months to forecast:\", min_value=3, max_value=24, value=6)\n",
        "        forecast_total_sales(df, periods=forecast_months)\n",
        "\n",
        "        st.header(\"Predicted Top-Selling Items\")\n",
        "        predict_top_items(df, model)\n",
        "\n",
        "        if trends_input:\n",
        "            st.header(\"Sales Boost Forecast Based on Entered Trends\")\n",
        "            sales_boost_forecast(df, trend_list)\n",
        "\n",
        "    else:\n",
        "        st.header(\"Compare Datasets\")\n",
        "        compare_multiple_datasets(datasets, dataset_labels)\n",
        "\n",
        "        individual_dataset_analytics(datasets, dataset_labels)\n",
        "\n",
        "        st.header(\"Correlate Trends with Sales Across Datasets\")\n",
        "        trends_input_correlation = st.text_input(\"Enter trends to correlate (comma-separated):\", key=\"trend_correlation\")\n",
        "        if trends_input_correlation:\n",
        "            trend_list_correlation = [trend.strip() for trend in trends_input_correlation.split(\",\")]\n",
        "            correlate_trends_with_datasets(datasets, dataset_labels, trend_list_correlation)\n",
        "            detect_best_dataset(datasets, dataset_labels, trend_list_correlation)\n",
        "\n",
        "            trend_impact_modeling(datasets, dataset_labels, trend_list_correlation)\n",
        "\n",
        "        st.header(\"Master Combined Forecast Across All Datasets\")\n",
        "        master_combined_forecast(datasets, dataset_labels)\n",
        "\n",
        "else:\n",
        "    st.info(\"Upload one or more CSV files to get started!\")\n",
        "\n",
        "# # ----------------------------------------\n",
        "# # UPDATED STREAMLIT APP Section (Full Analytics for Each Dataset)\n",
        "# # ----------------------------------------\n",
        "\n",
        "# st.title(\"From Hashtags to Hangars: Fashion Forecasting Dashboard\")\n",
        "\n",
        "# uploaded_files = st.file_uploader(\"Upload one or more Fashion Sales CSVs\", type=[\"csv\"], accept_multiple_files=True)\n",
        "\n",
        "# if uploaded_files:\n",
        "#     datasets = load_multiple_csv(uploaded_files)\n",
        "#     dataset_labels = [file.name for file in uploaded_files]\n",
        "\n",
        "#     st.header(\"Live Google Trends Scraper\")\n",
        "#     if st.button(\"Scrape Fashion Trends Now\"):\n",
        "#         scraped_trends = scrape_top_fashion_trends()\n",
        "#         if scraped_trends:\n",
        "#             st.session_state['scraped_trends'] = scraped_trends\n",
        "\n",
        "#     if 'scraped_trends' in st.session_state:\n",
        "#         selected_trends = st.multiselect(\"Select trends to forecast from scraped results:\", st.session_state['scraped_trends'])\n",
        "#         if selected_trends:\n",
        "#             forecast_multiple_trends(selected_trends)\n",
        "\n",
        "#     if len(datasets) == 1:\n",
        "#         df = datasets[0]\n",
        "#         visualize_sales(df)\n",
        "#         model = train_sales_predictors(df)\n",
        "\n",
        "#         st.header(\"Forecast Manual Trends\")\n",
        "#         trends_input = st.text_input(\"Enter multiple fashion trends separated by commas (e.g., barbiecore, grunge, Y2K)\")\n",
        "#         if trends_input:\n",
        "#             trend_list = [trend.strip() for trend in trends_input.split(\",\")]\n",
        "#             forecast_multiple_trends(trend_list)\n",
        "\n",
        "#         st.header(\"Future Sales Forecast\")\n",
        "#         forecast_months = st.slider(\"Select number of months to forecast:\", min_value=3, max_value=24, value=6)\n",
        "#         sales_forecast = forecast_total_sales(df, periods=forecast_months)\n",
        "\n",
        "#         st.header(\"Predicted Top-Selling Items\")\n",
        "#         predict_top_items(df, model)\n",
        "\n",
        "#     else:\n",
        "#         st.header(\"Compare Datasets\")\n",
        "#         compare_multiple_datasets(datasets, dataset_labels)\n",
        "\n",
        "#         st.header(\"Individual Dataset Analytics\")\n",
        "#         for df, label in zip(datasets, dataset_labels):\n",
        "#             st.subheader(f\"Analytics for {label}\")\n",
        "#             visualize_sales(df)\n",
        "#             model = train_sales_predictors(df)\n",
        "\n",
        "#             st.subheader(f\"Trend Forecasting for {label}\")\n",
        "#             trends_input = st.text_input(f\"Enter trends to forecast for {label} (comma-separated):\", key=f\"forecast_{label}\")\n",
        "#             if trends_input:\n",
        "#                 trend_list = [trend.strip() for trend in trends_input.split(\",\")]\n",
        "#                 forecast_multiple_trends(trend_list)\n",
        "\n",
        "#             st.subheader(f\"Future Sales Forecast for {label}\")\n",
        "#             forecast_months = st.slider(f\"Select forecast months for {label}:\", min_value=3, max_value=24, value=6, key=f\"months_{label}\")\n",
        "#             sales_forecast = forecast_total_sales(df, periods=forecast_months)\n",
        "\n",
        "#             st.subheader(f\"Predicted Top Items for {label}\")\n",
        "#             predict_top_items(df, model)\n",
        "\n",
        "#         st.header(\"🔗 Correlate Trends with Sales Across Datasets\")\n",
        "#         trends_input = st.text_input(\"Enter trends to correlate (comma-separated):\", key=\"trend_correlation\")\n",
        "#         if trends_input:\n",
        "#             trend_list = [trend.strip() for trend in trends_input.split(\",\")]\n",
        "#             correlate_trends_with_datasets(datasets, dataset_labels, trend_list)\n",
        "#             detect_best_dataset(datasets, dataset_labels, trend_list)\n",
        "\n",
        "#         st.header(\"Master Combined Forecast Across All Datasets\")\n",
        "#         master_combined_forecast(datasets, dataset_labels)\n",
        "# else:\n",
        "#     st.info(\"Upload one or more CSV files to get started!\")\n"
      ],
      "metadata": {
        "id": "Ge--UhQBmzvj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "s_hdAro9m4lV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}